{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing data with replacing it with mode\n",
    "def replace_missing_val(census_data):\n",
    "    census_data['workclass'].replace(np.NaN, census_data['workclass'].mode()[0] , inplace=True )\n",
    "    census_data['occupation'].replace(np.NaN, census_data['occupation'].mode()[0] , inplace=True )\n",
    "    census_data['native-country'].replace(np.NaN, census_data['native-country'].mode()[0] , inplace=True )\n",
    "    return census_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for calculating probability using PDF\n",
    "def apply_pdf(x, mean, std_dev):\n",
    "#     return (math.erf((x-mean)/(std_dev * math.sqrt(2))))/2    \n",
    "    expo = math.exp(-(math.pow(x-mean,2)/(2*math.pow(std_dev,2))))\n",
    "    return (1 / (math.sqrt(2*math.pi) * std_dev)) * expo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume atributes follows Gaussian distribution\n",
    "def NB_Gaussian_fit(training_set):\n",
    "    # dictioanry to store weights\n",
    "    weightdict = {}   \n",
    "    continues_attributes = ['age','fnlwgt','education-num','capital-loss','capital-gain','hours-per-week']\n",
    "    # separate dataframe according to class labels\n",
    "    yes_df = training_set.loc[training_set['class'] == ' >50K']\n",
    "    no_df = training_set.loc[training_set['class'] == ' <=50K']    \n",
    "        \n",
    "    training_set = training_set.drop(labels= 'class', axis=1)\n",
    "    \n",
    "    for label, content in training_set.iteritems(): \n",
    "        if label in continues_attributes:\n",
    "            weightdict[label] = {}\n",
    "            weightdict[label]['yes'] = {}\n",
    "            weightdict[label]['no'] = {}\n",
    "            weightdict[label]['yes']['std_dev'] = yes_df[label].std()\n",
    "            weightdict[label]['yes']['mean'] = yes_df[label].mean()\n",
    "            weightdict[label]['no']['std_dev'] = no_df[label].std()\n",
    "            weightdict[label]['no']['mean'] = no_df[label].mean()\n",
    "            \n",
    "        else:\n",
    "            if label not in weightdict.keys():\n",
    "                weightdict[label]={}\n",
    "                for val in content: # add all unique value of the attribute to dictionary key\n",
    "                    if val not in weightdict[label].keys():\n",
    "                        weightdict[label][val] = {} \n",
    "                        #store only count of records in both class for feature\n",
    "                        weightdict[label][val]['yes'] = sum(y for y in yes_df[label] == val )\n",
    "                        weightdict[label][val]['no'] = sum(n for n in no_df[label] == val)          \n",
    "         \n",
    "       \n",
    "    weightdict['total_yes_label'] = len(yes_df)\n",
    "    weightdict['total_no_label'] = len(no_df)  \n",
    "#     print(weightdict)\n",
    "    return weightdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to predict labels\n",
    "\n",
    "def NB_Gaussian_predict(test_set, weight_dict):\n",
    "#     binned_test_set = binningDF(test_set)\n",
    "    continues_attributes = ['age','fnlwgt','education-num','capital-loss','capital-gain','hours-per-week']\n",
    "    predicted_label = []\n",
    "    for index, content in test_set.iterrows():\n",
    "        yes_prob = []\n",
    "        no_prob = []\n",
    "        total_yes_targets = weight_dict['total_yes_label']\n",
    "        total_no_targets = weight_dict['total_no_label']\n",
    "        for label in content.keys():\n",
    "            if label in continues_attributes:\n",
    "                yes_prob.append(apply_pdf(content[label],weight_dict[label]['yes']['mean'], weight_dict[label]['yes']['std_dev']))\n",
    "                no_prob.append(apply_pdf(content[label],weight_dict[label]['no']['mean'], weight_dict[label]['no']['std_dev']))\n",
    "            else:\n",
    "                \n",
    "                if content[label] in weight_dict[label].keys():\n",
    "                    if(weight_dict[label][content[label]]['yes'] and weight_dict[label][content[label]]['no']):                        \n",
    "                        yes_prob.append(weight_dict[label][content[label]]['yes'] /total_yes_targets)\n",
    "                        no_prob.append(weight_dict[label][content[label]]['no'] /total_no_targets)\n",
    "                    else:\n",
    "                        #Laplacian correction for feature present in only one class\n",
    "                        yes_prob.append((weight_dict[label][content[label]]['yes'] +1) /(total_yes_targets + len(weight_dict[label])))\n",
    "                        no_prob.append((weight_dict[label][content[label]]['no']+1) /(total_no_targets + len(weight_dict[label])))              \n",
    "                else:\n",
    "                    #apply laplacian correction for feature not existing in training set\n",
    "                    yes_prob.append(1/total_yes_targets + len(weight_dict[label]))\n",
    "                    no_prob.append(1/total_no_targets + len(weight_dict[label]))\n",
    "                   \n",
    "        predicted_yes = np.prod(np.array(yes_prob)) * (total_yes_targets/(total_yes_targets+total_no_targets))\n",
    "        predicted_no = np.prod(np.array(no_prob)) * (total_no_targets/(total_yes_targets+total_no_targets))\n",
    "        \n",
    "        if predicted_yes >= predicted_no:\n",
    "            predicted_label.append(' >50K')\n",
    "        else:\n",
    "            predicted_label.append(' <=50K')\n",
    "            \n",
    "    return predicted_label       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cv_Gaussian(data, k):\n",
    "    accuracy_list = []\n",
    "    F1_score = []\n",
    "    MCC_list = [] \n",
    "    split_ratio = k/100\n",
    "    sub_data = []    \n",
    "    # divide data into k sub-dataframes    \n",
    "    for i in range(0, k):\n",
    "        sub_data.append(data.sample(frac= 0.1) )      \n",
    "                \n",
    "    for i in range(0,k):\n",
    "        test_split = sub_data[i]\n",
    "        train_split = pd.DataFrame()\n",
    "        for j in range(0, k):\n",
    "            if (j != i):   \n",
    "                train_split = pd.concat([train_split,sub_data[j]])\n",
    "        \n",
    "        \n",
    "        test_data_label = test_split['class']\n",
    "        test_split = test_split.drop(labels= 'class', axis=1)\n",
    "        # train the model to calculate the weights\n",
    "        weightdict = NB_Gaussian_fit(train_split)\n",
    "        # predict the labels for test data\n",
    "        predicted_val = NB_Gaussian_predict(test_split,weightdict)\n",
    "        true_pos = len([i for i, j in zip(test_data_label,predicted_val) if i == j and j == ' >50K'])\n",
    "        true_neg = len([i for i, j in zip(test_data_label,predicted_val) if i == j and j == ' <=50K'])\n",
    "        false_pos = len([i for i, j in zip(test_data_label,predicted_val) if i != j and j == ' >50K'])\n",
    "        false_neg = len([i for i, j in zip(test_data_label,predicted_val) if i != j and j == ' <=50K'])\n",
    "        precision = true_pos/(true_pos+false_pos)\n",
    "        recall = true_pos/(true_pos+false_neg)\n",
    "                \n",
    "        accuracy = len([i for i, j in zip(test_data_label,predicted_val) if i == j])/len(test_data_label)\n",
    "        F1_score.append((2*precision*recall)/(precision+recall)) \n",
    "        #calculate matthews correlation coefficient \n",
    "        Mcc_denominator = math.sqrt((true_pos+false_pos) * (true_pos+false_neg)*(true_neg+false_neg)*(false_pos+true_neg))\n",
    "        MCC = ((true_pos*true_neg) - (false_pos*false_neg))/Mcc_denominator\n",
    "        MCC_list.append(MCC)\n",
    "        \n",
    "        accuracy_list.append(accuracy)\n",
    "        \n",
    "    return (accuracy_list,F1_score, MCC_list)      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Naive_Bayesian_model_Gauusian(data, k, remove_missing_value):   \n",
    "    \n",
    "    if remove_missing_value:\n",
    "        data.dropna(inplace=True)\n",
    "        print(\"Removed missing values from dataset\")\n",
    "    else:\n",
    "        data = replace_missing_val(data)\n",
    "        print(\"Replaced missing values from dataset with mode of the attributes\")\n",
    "    \n",
    "    accuracy_list, F1_score, MCC_list = k_fold_cv_Gaussian(data, k)\n",
    "    print(\"avg accuracy of the model :\", (sum(accuracy_list)/len(accuracy_list)))\n",
    "    print(\"F1-measure is :\", sum(F1_score)/len(F1_score))\n",
    "    print(\"Matthews corelation coefficient :\", sum(MCC_list)/len(MCC_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the data using pandas\n",
    "header = ['age', 'workclass','fnlwgt', 'education','education-num','marital-status','occupation','relationship','race','sex',\n",
    "          'capital-gain','capital-loss','hours-per-week','native-country','class']         \n",
    "census_data = pd.read_table('adult.data',sep=',', header=None)\n",
    "census_data.columns = header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of dataset  (32561, 15)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of dataset \", census_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of records of missing values in attributes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "age                  0\n",
       "workclass         1836\n",
       "fnlwgt               0\n",
       "education            0\n",
       "education-num        0\n",
       "marital-status       0\n",
       "occupation        1843\n",
       "relationship         0\n",
       "race                 0\n",
       "sex                  0\n",
       "capital-gain         0\n",
       "capital-loss         0\n",
       "hours-per-week       0\n",
       "native-country     583\n",
       "class                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the number of missing values in attributes\n",
    "census_data.replace(' ?', np.NaN, inplace=True)\n",
    "print(\"number of records of missing values in attributes\")    \n",
    "census_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed missing values from dataset\n",
      "avg accuracy of the model : 0.8233090185676393\n",
      "F1-measure is : 0.5896543113110007\n",
      "Matthews corelation coefficient : 0.4941266852477363\n"
     ]
    }
   ],
   "source": [
    "# parameters for model are data_set, value of K for K fold cv and remove_missing_value is true or false \n",
    "\n",
    "# Model with removed missing values records\n",
    "Naive_Bayesian_model_Gauusian(census_data, 10, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced missing values from dataset with mode of the attributes\n",
      "avg accuracy of the model : 0.8272877984084881\n",
      "F1-measure is : 0.592932800656593\n",
      "Matthews corelation coefficient : 0.5002828207652984\n"
     ]
    }
   ],
   "source": [
    "#Model with replaced missing values\n",
    "Naive_Bayesian_model_Gauusian(census_data, 10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
